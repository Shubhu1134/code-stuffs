# 🧠 AI Learning Journey (June – Dec 2025)

Welcome to my AI learning folder! This contains my daily progress, projects, and experiments on the path to becoming an AI developer.

## 📅 Day 1 – Python Basics

- ✅ Learned: Variables, conditionals, loops, and functions
- 📝 File: `day1_basics.py`

## 📁 Projects (Coming soon)

- House Price Predictor (Regression)
- Spam Classifier (NLP)

## 📅 Day 2 – Python Data Structures

- ✅ Learned: List, Tuple, Set, Dictionary
- 📝 File: `day2_data_structures.py`

## 📅 Day 3 – NumPy Basics

- ✅ Learned: Arrays, operations, shapes, slicing, broadcasting
- 📝 File: `day3_numpy_basics.py`

## 📅 Day 4 – Pandas Basics

- ✅ Learned: Creating DataFrames, filtering, reading CSVs
- 📝 File: `day4_pandas_basics.py`

## 📅 Day 5 – Data Preprocessing (Pandas Advanced)

- ✅ Learned: Missing values, drop/fill columns, encoding
- 🧾 Dataset: Titanic CSV
- 📝 File: `day5_data_preprocessing.py`

## 📅 Day 6 – Data Visualization

- ✅ Learned: Matplotlib + Seaborn for data insights
- 📈 Visualized: Survival count, age distribution, correlation heatmap
- 📝 File: `day6_visualization.py`
- 🖼️ Output: Plots saved in `datasets/`

## 📅 Day 7 – Intro to Machine Learning

- ✅ Learned: Supervised vs Unsupervised, ML pipeline
- 🧪 Model: Logistic Regression (Binary Classification)
- 🎯 Accuracy: ~0.78 on Titanic data
- 📝 File: `day7_intro_to_ml.py`

## 📅 Day 8 – Model Evaluation

- ✅ Learned: Confusion matrix, precision, recall, F1, ROC
- 📊 Visualized: Evaluation metrics for Titanic model
- 📝 File: `day8_model_evaluation.py`
- 🖼️ Output: Plots saved in `datasets/`

## 📅 Day 9 – Model Improvement: Feature Selection + Scaling

- ✅ Learned: Manual feature selection, correlation heatmap
- 📏 Scaled data: MinMaxScaler & StandardScaler
- 📊 Compared model accuracy with and without scaling
- 📝 File: `day9_feature_selection_scaling.py`

## 📅 Day 10 – K-Nearest Neighbors (KNN)

- ✅ Learned: Theory of KNN + distance-based prediction
- 🛠️ Built: Manual KNN + `KNeighborsClassifier` from sklearn
- 🧪 Compared predictions and accuracy
- 📝 File: `day10_knn_model.py`

## 📅 Day 11 – Decision Trees

- ✅ Learned: Decision nodes, Gini, Entropy, tree depth
- 🌳 Visualized: Tree structure using `plot_tree`
- 📊 Evaluation: Accuracy + classification report
- 📝 File: `day11_decision_tree.py`

## 📅 Day 12 – Random Forest

- ✅ Learned: Ensemble learning, bagging, feature randomness
- 🌲 Trained: `RandomForestClassifier` with 100 trees
- 📈 Output: Feature importance plot saved
- 📝 File: `day12_random_forest.py`

## 📅 Day 13 – Hyperparameter Tuning with Grid Search

- 🧠 Learned: Hyperparameters, GridSearchCV, cross-validation
- 🛠️ Tuned: Random Forest with different depths and estimators
- 🏆 Output: Best model accuracy and hyperparameters
- 📝 File: `day13_grid_search_tuning.py`

## 📅 Day 14 – Support Vector Machines (SVM)

- ✅ Learned: Margin maximization, support vectors, kernel trick
- 🧪 Tested: `SVC` with `rbf` kernel
- 🎯 Achieved: High accuracy with standardized features
- 📝 File: `day14_svm_model.py`

## 📅 Day 15 – Naive Bayes Classifier

- ✅ Learned: Bayes’ Theorem, Naive independence assumption
- 🧪 Tested: `GaussianNB` on Titanic dataset
- 📝 File: `day15_naive_bayes.py`
