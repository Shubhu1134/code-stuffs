# ğŸ§  AI Learning Journey (June â€“ Dec 2025)

Welcome to my AI learning folder! This contains my daily progress, projects, and experiments on the path to becoming an AI developer.

## ğŸ“… Day 1 â€“ Python Basics

- âœ… Learned: Variables, conditionals, loops, and functions
- ğŸ“ File: `day1_basics.py`

## ğŸ“ Projects (Coming soon)

- House Price Predictor (Regression)
- Spam Classifier (NLP)

## ğŸ“… Day 2 â€“ Python Data Structures

- âœ… Learned: List, Tuple, Set, Dictionary
- ğŸ“ File: `day2_data_structures.py`

## ğŸ“… Day 3 â€“ NumPy Basics

- âœ… Learned: Arrays, operations, shapes, slicing, broadcasting
- ğŸ“ File: `day3_numpy_basics.py`

## ğŸ“… Day 4 â€“ Pandas Basics

- âœ… Learned: Creating DataFrames, filtering, reading CSVs
- ğŸ“ File: `day4_pandas_basics.py`

## ğŸ“… Day 5 â€“ Data Preprocessing (Pandas Advanced)

- âœ… Learned: Missing values, drop/fill columns, encoding
- ğŸ§¾ Dataset: Titanic CSV
- ğŸ“ File: `day5_data_preprocessing.py`

## ğŸ“… Day 6 â€“ Data Visualization

- âœ… Learned: Matplotlib + Seaborn for data insights
- ğŸ“ˆ Visualized: Survival count, age distribution, correlation heatmap
- ğŸ“ File: `day6_visualization.py`
- ğŸ–¼ï¸ Output: Plots saved in `datasets/`

## ğŸ“… Day 7 â€“ Intro to Machine Learning

- âœ… Learned: Supervised vs Unsupervised, ML pipeline
- ğŸ§ª Model: Logistic Regression (Binary Classification)
- ğŸ¯ Accuracy: ~0.78 on Titanic data
- ğŸ“ File: `day7_intro_to_ml.py`

## ğŸ“… Day 8 â€“ Model Evaluation

- âœ… Learned: Confusion matrix, precision, recall, F1, ROC
- ğŸ“Š Visualized: Evaluation metrics for Titanic model
- ğŸ“ File: `day8_model_evaluation.py`
- ğŸ–¼ï¸ Output: Plots saved in `datasets/`

## ğŸ“… Day 9 â€“ Model Improvement: Feature Selection + Scaling

- âœ… Learned: Manual feature selection, correlation heatmap
- ğŸ“ Scaled data: MinMaxScaler & StandardScaler
- ğŸ“Š Compared model accuracy with and without scaling
- ğŸ“ File: `day9_feature_selection_scaling.py`

## ğŸ“… Day 10 â€“ K-Nearest Neighbors (KNN)

- âœ… Learned: Theory of KNN + distance-based prediction
- ğŸ› ï¸ Built: Manual KNN + `KNeighborsClassifier` from sklearn
- ğŸ§ª Compared predictions and accuracy
- ğŸ“ File: `day10_knn_model.py`

## ğŸ“… Day 11 â€“ Decision Trees

- âœ… Learned: Decision nodes, Gini, Entropy, tree depth
- ğŸŒ³ Visualized: Tree structure using `plot_tree`
- ğŸ“Š Evaluation: Accuracy + classification report
- ğŸ“ File: `day11_decision_tree.py`

## ğŸ“… Day 12 â€“ Random Forest

- âœ… Learned: Ensemble learning, bagging, feature randomness
- ğŸŒ² Trained: `RandomForestClassifier` with 100 trees
- ğŸ“ˆ Output: Feature importance plot saved
- ğŸ“ File: `day12_random_forest.py`

## ğŸ“… Day 13 â€“ Hyperparameter Tuning with Grid Search

- ğŸ§  Learned: Hyperparameters, GridSearchCV, cross-validation
- ğŸ› ï¸ Tuned: Random Forest with different depths and estimators
- ğŸ† Output: Best model accuracy and hyperparameters
- ğŸ“ File: `day13_grid_search_tuning.py`

## ğŸ“… Day 14 â€“ Support Vector Machines (SVM)

- âœ… Learned: Margin maximization, support vectors, kernel trick
- ğŸ§ª Tested: `SVC` with `rbf` kernel
- ğŸ¯ Achieved: High accuracy with standardized features
- ğŸ“ File: `day14_svm_model.py`

## ğŸ“… Day 15 â€“ Naive Bayes Classifier

- âœ… Learned: Bayesâ€™ Theorem, Naive independence assumption
- ğŸ§ª Tested: `GaussianNB` on Titanic dataset
- ğŸ“ File: `day15_naive_bayes.py`
